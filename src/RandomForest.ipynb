{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ5DI9xpTntL",
        "outputId": "a2b94001-8376-4b4a-99f5-e7293ee7a7c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train: 1990-01-01 to 2015-12-31 | Validation: 2016-01-01 to 2016-12-31 | Overall R^2: 0.2009 | Tuned: {'max_depth': 7, 'n_estimators': 150}\n",
            "Train: 1991-01-01 to 2016-12-31 | Validation: 2017-01-01 to 2017-12-31 | Overall R^2: 0.1070 | Tuned: {'max_depth': 7, 'n_estimators': 50}\n",
            "Train: 1992-01-01 to 2017-12-31 | Validation: 2018-01-01 to 2018-12-31 | Overall R^2: 0.1902 | Tuned: {'max_depth': None, 'n_estimators': 150}\n",
            "Train: 1993-01-01 to 2018-12-31 | Validation: 2019-01-01 to 2019-12-31 | Overall R^2: 0.1768 | Using best_params: {'max_depth': None, 'n_estimators': 150}\n",
            "Train: 1994-01-01 to 2019-12-31 | Validation: 2020-01-01 to 2020-12-31 | Overall R^2: -0.0693 | Using best_params: {'max_depth': None, 'n_estimators': 150}\n",
            "Train: 1995-01-01 to 2020-12-31 | Validation: 2021-01-01 to 2021-12-31 | Overall R^2: 0.0167 | Using best_params: {'max_depth': None, 'n_estimators': 150}\n",
            "Train: 1996-01-01 to 2021-12-31 | Validation: 2022-01-01 to 2022-12-31 | Overall R^2: 0.0634 | Using best_params: {'max_depth': None, 'n_estimators': 150}\n",
            "Train: 1997-01-01 to 2022-12-31 | Validation: 2023-01-01 to 2023-12-29 | Overall R^2: 0.1046 | Using best_params: {'max_depth': None, 'n_estimators': 150}\n",
            "\n",
            "Summary of Rolling Window Results with Validation:\n",
            "  train_start  train_end  val_start    val_end  overall_r2  \\\n",
            "0  1990-01-01 2015-12-31 2016-01-01 2016-12-31    0.200939   \n",
            "1  1991-01-01 2016-12-31 2017-01-01 2017-12-31    0.106976   \n",
            "2  1992-01-01 2017-12-31 2018-01-01 2018-12-31    0.190167   \n",
            "3  1993-01-01 2018-12-31 2019-01-01 2019-12-31    0.176764   \n",
            "4  1994-01-01 2019-12-31 2020-01-01 2020-12-31   -0.069314   \n",
            "5  1995-01-01 2020-12-31 2021-01-01 2021-12-31    0.016671   \n",
            "6  1996-01-01 2021-12-31 2022-01-01 2022-12-31    0.063429   \n",
            "7  1997-01-01 2022-12-31 2023-01-01 2023-12-29    0.104628   \n",
            "\n",
            "                                best_params  \\\n",
            "0     {'max_depth': 7, 'n_estimators': 150}   \n",
            "1      {'max_depth': 7, 'n_estimators': 50}   \n",
            "2  {'max_depth': None, 'n_estimators': 150}   \n",
            "3  {'max_depth': None, 'n_estimators': 150}   \n",
            "4  {'max_depth': None, 'n_estimators': 150}   \n",
            "5  {'max_depth': None, 'n_estimators': 150}   \n",
            "6  {'max_depth': None, 'n_estimators': 150}   \n",
            "7  {'max_depth': None, 'n_estimators': 150}   \n",
            "\n",
            "                                         tuning_info  \n",
            "0       Tuned: {'max_depth': 7, 'n_estimators': 150}  \n",
            "1        Tuned: {'max_depth': 7, 'n_estimators': 50}  \n",
            "2    Tuned: {'max_depth': None, 'n_estimators': 150}  \n",
            "3  Using best_params: {'max_depth': None, 'n_esti...  \n",
            "4  Using best_params: {'max_depth': None, 'n_esti...  \n",
            "5  Using best_params: {'max_depth': None, 'n_esti...  \n",
            "6  Using best_params: {'max_depth': None, 'n_esti...  \n",
            "7  Using best_params: {'max_depth': None, 'n_esti...  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from datetime import datetime\n",
        "# ----------------------------\n",
        "# 1. Data Loading and Preprocessing\n",
        "# ----------------------------\n",
        "df = pd.read_csv('../data/weekly_df_with_tickers.csv', parse_dates=['Date'])\n",
        "df.sort_values('Date', inplace=True)\n",
        "df.set_index('Date', inplace=True)\n",
        "df = df.replace([np.inf, -np.inf], np.nan)\n",
        "df = df.dropna(subset=['mvel1'])\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Define the Rolling Window Forecasting Function with Validation (no monthly R²)\n",
        "# ----------------------------\n",
        "def rolling_window_forecast_with_validation(df, base_model, initial_train_start, initial_train_end,\n",
        "                                              validation_window_years=1, rolling_step=1, update_threshold=2019):\n",
        "    \"\"\"\n",
        "    Performs rolling window forecasting with a dedicated validation period for hyperparameter tuning.\n",
        "\n",
        "    For each iteration:\n",
        "      - The training period runs from train_start to train_end.\n",
        "      - The validation period immediately follows (with a length of validation_window_years\n",
        "        or until the maximum available date, if the window is incomplete).\n",
        "      - If the validation period's start year is less than update_threshold (here 2019),\n",
        "        hyperparameter tuning is performed (via GridSearchCV) on the training data.\n",
        "      - Otherwise, the previously tuned hyperparameters are used.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas.DataFrame\n",
        "        DataFrame containing the data (must have a DateTimeIndex).\n",
        "    base_model : scikit-learn regressor\n",
        "        The base model (e.g., RandomForestRegressor).\n",
        "    initial_train_start : str or datetime\n",
        "        Start date for the initial training period.\n",
        "    initial_train_end : str or datetime\n",
        "        End date for the initial training period.\n",
        "    validation_window_years : int, default=1\n",
        "        Length (in years) of the validation period.\n",
        "    rolling_step : int, default=1\n",
        "        Number of years to shift the window for each iteration.\n",
        "    update_threshold : int\n",
        "        Hyperparameter tuning is performed if the validation period's start year is less than this threshold.\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    results : list of dicts\n",
        "        Each dict contains the window’s training/validation dates, performance metrics,\n",
        "        and the hyperparameters used.\n",
        "    \"\"\"\n",
        "    results = []\n",
        "    best_params = None  # To store the tuned hyperparameters\n",
        "\n",
        "    # Convert dates to Timestamps.\n",
        "    train_start = pd.to_datetime(initial_train_start)\n",
        "    train_end = pd.to_datetime(initial_train_end)\n",
        "    val_start = train_end + pd.DateOffset(days=1)\n",
        "    val_end = val_start + pd.DateOffset(years=validation_window_years) - pd.DateOffset(days=1)\n",
        "\n",
        "    max_date = df.index.max()\n",
        "\n",
        "    # Define feature columns (exclude target and ticker)\n",
        "    non_feature_cols = ['risk_premium', 'Ticker']\n",
        "    feature_cols = [col for col in df.columns if col not in non_feature_cols]\n",
        "\n",
        "    while train_start < max_date:\n",
        "        # If the planned validation end exceeds available data, adjust it.\n",
        "        if val_end > max_date:\n",
        "            val_end = max_date\n",
        "\n",
        "        # Extract training and validation data for the current window.\n",
        "        train_data = df.loc[(df.index >= train_start) & (df.index <= train_end)]\n",
        "        val_data = df.loc[(df.index >= val_start) & (df.index <= val_end)]\n",
        "        if train_data.empty or val_data.empty:\n",
        "            break\n",
        "\n",
        "        X_train = train_data[feature_cols]\n",
        "        y_train = train_data['risk_premium']\n",
        "        X_val = val_data[feature_cols]\n",
        "        y_val = val_data['risk_premium']\n",
        "\n",
        "        # If the validation period starts before the update threshold, perform hyperparameter tuning.\n",
        "        if val_start.year < update_threshold:\n",
        "            param_grid = {\n",
        "                'n_estimators': [50, 100, 150],\n",
        "                'max_depth': [3, 5, 7, None]\n",
        "            }\n",
        "            grid = GridSearchCV(estimator=base_model, param_grid=param_grid,\n",
        "                                scoring='r2', cv=3, n_jobs=-1)\n",
        "            grid.fit(X_train, y_train)\n",
        "            best_params = grid.best_params_\n",
        "            model_tuned = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "            model_tuned.fit(X_train, y_train)\n",
        "            y_pred = model_tuned.predict(X_val)\n",
        "            tuning_info = f\"Tuned: {best_params}\"\n",
        "        else:\n",
        "            # For validation periods starting in or after the update threshold, use the previously tuned parameters.\n",
        "            if best_params is not None:\n",
        "                model_tuned = RandomForestRegressor(**best_params, random_state=42, n_jobs=-1)\n",
        "                model_tuned.fit(X_train, y_train)\n",
        "                y_pred = model_tuned.predict(X_val)\n",
        "                tuning_info = f\"Using best_params: {best_params}\"\n",
        "            else:\n",
        "                # Fallback: if no tuning was done previously, use the base model.\n",
        "                base_model.fit(X_train, y_train)\n",
        "                y_pred = base_model.predict(X_val)\n",
        "                tuning_info = \"No tuning performed\"\n",
        "\n",
        "        overall_r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "        results.append({\n",
        "            'train_start': train_start,\n",
        "            'train_end': train_end,\n",
        "            'val_start': val_start,\n",
        "            'val_end': val_end,\n",
        "            'overall_r2': overall_r2,\n",
        "            'best_params': best_params,\n",
        "            'tuning_info': tuning_info\n",
        "        })\n",
        "\n",
        "        print(f\"Train: {train_start.date()} to {train_end.date()} | \"\n",
        "              f\"Validation: {val_start.date()} to {val_end.date()} | \"\n",
        "              f\"Overall R^2: {overall_r2:.4f} | {tuning_info}\")\n",
        "\n",
        "        # Update the window by shifting each boundary forward by rolling_step years.\n",
        "        train_start += pd.DateOffset(years=rolling_step)\n",
        "        train_end += pd.DateOffset(years=rolling_step)\n",
        "        val_start += pd.DateOffset(years=rolling_step)\n",
        "        val_end += pd.DateOffset(years=rolling_step)\n",
        "\n",
        "    return results\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Model Initialization and Running the Forecast\n",
        "# ----------------------------\n",
        "# Define the base model (without fixed hyperparameters).\n",
        "base_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# Run the rolling window forecast with validation.\n",
        "results = rolling_window_forecast_with_validation(\n",
        "    df,\n",
        "    base_model,\n",
        "    initial_train_start='1990-01-01',\n",
        "    initial_train_end='2015-12-31',\n",
        "    validation_window_years=1,   # validation period of one year\n",
        "    rolling_step=1,\n",
        "    update_threshold=2019        # tune hyperparameters if validation period starts before 2019\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Post-Processing\n",
        "# ----------------------------\n",
        "results_df = pd.DataFrame([{\n",
        "    'train_start': r['train_start'],\n",
        "    'train_end': r['train_end'],\n",
        "    'val_start': r['val_start'],\n",
        "    'val_end': r['val_end'],\n",
        "    'overall_r2': r['overall_r2'],\n",
        "    'best_params': r['best_params'],\n",
        "    'tuning_info': r['tuning_info']\n",
        "} for r in results])\n",
        "\n",
        "print(\"\\nSummary of Rolling Window Results with Validation:\")\n",
        "print(results_df)\n",
        "\n",
        "# Save the results to a CSV file.\n",
        "results_df.to_csv(\"rolling_window_results_with_validation.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
